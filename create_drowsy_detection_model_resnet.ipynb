{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T11:39:57.544428Z",
     "start_time": "2024-04-16T11:39:54.980265Z"
    }
   },
   "source": [
    "import os, cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:39:57.559428Z",
     "start_time": "2024-04-16T11:39:57.545429Z"
    }
   },
   "cell_type": "code",
   "source": "data_files_list = ['result_bus_20240226-112104.csv', 'result_passenger_20240226-112405.csv', 'result_taxi_20240226-112648.csv', 'result_truck_20240226-112812.csv']",
   "id": "8f99d7a2a36f3a85",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:39:57.710438Z",
     "start_time": "2024-04-16T11:39:57.560429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = pd.DataFrame()\n",
    "test_dataset = pd.DataFrame()\n",
    "\n",
    "for data_file in data_files_list:\n",
    "    data = pd.read_csv('analysis_data' + os.sep + data_file)\n",
    "    train_data, test_data = train_test_split(data, test_size=0.1, random_state=0)\n",
    "    train_dataset = pd.concat([train_dataset, train_data])\n",
    "    test_dataset = pd.concat([test_dataset, test_data])\n",
    "    \n",
    "train_dataset.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "test_dataset.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "data_columns = train_dataset.columns.to_list()[0:]\n",
    "train_dataset.head()"
   ],
   "id": "255433b4ed8fde07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          file_name  face_pt1_x_pos  face_pt1_y_pos  \\\n",
       "6581  R_234_60_M_19_M1_G1_C0_03.jpg           211.0           434.0   \n",
       "971   R_218_50_M_17_M1_G0_C0_12.jpg           320.0           468.0   \n",
       "3776  R_226_30_M_17_M1_G1_C1_17.jpg           284.0           506.0   \n",
       "5292  R_231_50_M_09_M1_G0_C0_14.jpg           144.0           447.0   \n",
       "5097  R_230_40_M_19_M1_G1_C0_18.jpg            41.0           582.0   \n",
       "\n",
       "      face_pt2_x_pos  face_pt2_y_pos  left_eye_pt1_x_pos  left_eye_pt1_y_pos  \\\n",
       "6581           483.0           910.0               261.0               599.0   \n",
       "971            566.0           932.0               380.0               635.0   \n",
       "3776           600.0           942.0               370.0               633.0   \n",
       "5292           474.0          1013.0               209.0               669.0   \n",
       "5097           320.0          1028.0               169.0               685.0   \n",
       "\n",
       "      left_eye_pt2_x_pos  left_eye_pt2_y_pos  right_eye_pt1_x_pos  ...  \\\n",
       "6581               304.0               610.0                377.0  ...   \n",
       "971                418.0               656.0                487.0  ...   \n",
       "3776               396.0               647.0                478.0  ...   \n",
       "5292               228.0               695.0                295.0  ...   \n",
       "5097               199.0               730.0                194.0  ...   \n",
       "\n",
       "      target_right_eye_pt1_y_pos  target_right_eye_pt2_x  \\\n",
       "6581                      587.82                  425.23   \n",
       "971                       627.46                  544.69   \n",
       "3776                      629.95                  523.56   \n",
       "5292                      656.88                  369.80   \n",
       "5097                      705.04                  240.05   \n",
       "\n",
       "      target_right_eye_pt2_y_pos  exist_mask  exist_glasses  face_visible  \\\n",
       "6581                      616.64           1              1             1   \n",
       "971                       654.72           1              0             1   \n",
       "3776                      651.35           1              1             1   \n",
       "5292                      691.17           1              0             1   \n",
       "5097                      732.24           1              1             1   \n",
       "\n",
       "      left_eye_visible  left_eye_opened  right_eye_visible  right_eye_opened  \n",
       "6581                 1                1                  1                 1  \n",
       "971                  1                1                  1                 1  \n",
       "3776                 1                1                  1                 1  \n",
       "5292                 1                1                  1                 1  \n",
       "5097                 1                1                  1                 1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>face_pt1_x_pos</th>\n",
       "      <th>face_pt1_y_pos</th>\n",
       "      <th>face_pt2_x_pos</th>\n",
       "      <th>face_pt2_y_pos</th>\n",
       "      <th>left_eye_pt1_x_pos</th>\n",
       "      <th>left_eye_pt1_y_pos</th>\n",
       "      <th>left_eye_pt2_x_pos</th>\n",
       "      <th>left_eye_pt2_y_pos</th>\n",
       "      <th>right_eye_pt1_x_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>target_right_eye_pt1_y_pos</th>\n",
       "      <th>target_right_eye_pt2_x</th>\n",
       "      <th>target_right_eye_pt2_y_pos</th>\n",
       "      <th>exist_mask</th>\n",
       "      <th>exist_glasses</th>\n",
       "      <th>face_visible</th>\n",
       "      <th>left_eye_visible</th>\n",
       "      <th>left_eye_opened</th>\n",
       "      <th>right_eye_visible</th>\n",
       "      <th>right_eye_opened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6581</th>\n",
       "      <td>R_234_60_M_19_M1_G1_C0_03.jpg</td>\n",
       "      <td>211.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>587.82</td>\n",
       "      <td>425.23</td>\n",
       "      <td>616.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>R_218_50_M_17_M1_G0_C0_12.jpg</td>\n",
       "      <td>320.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>...</td>\n",
       "      <td>627.46</td>\n",
       "      <td>544.69</td>\n",
       "      <td>654.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>R_226_30_M_17_M1_G1_C1_17.jpg</td>\n",
       "      <td>284.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>...</td>\n",
       "      <td>629.95</td>\n",
       "      <td>523.56</td>\n",
       "      <td>651.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>R_231_50_M_09_M1_G0_C0_14.jpg</td>\n",
       "      <td>144.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>...</td>\n",
       "      <td>656.88</td>\n",
       "      <td>369.80</td>\n",
       "      <td>691.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>R_230_40_M_19_M1_G1_C0_18.jpg</td>\n",
       "      <td>41.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>...</td>\n",
       "      <td>705.04</td>\n",
       "      <td>240.05</td>\n",
       "      <td>732.24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:39:57.725438Z",
     "start_time": "2024-04-16T11:39:57.711438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_column_names = data_columns[5:9]\n",
    "target_column_names = [data_columns[38], data_columns[40]]"
   ],
   "id": "b50e844d350e7a90",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:39:57.740442Z",
     "start_time": "2024-04-16T11:39:57.727440Z"
    }
   },
   "cell_type": "code",
   "source": "feature_column_names",
   "id": "288d520495611c7b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left_eye_pt1_x_pos',\n",
       " 'left_eye_pt1_y_pos',\n",
       " 'left_eye_pt2_x_pos',\n",
       " 'left_eye_pt2_y_pos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:39:57.755436Z",
     "start_time": "2024-04-16T11:39:57.742438Z"
    }
   },
   "cell_type": "code",
   "source": "target_column_names",
   "id": "63d1cf0b1873ae8c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left_eye_opened', 'right_eye_opened']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:39:57.770436Z",
     "start_time": "2024-04-16T11:39:57.756440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataModulePt(Dataset):\n",
    "    def __init__(self, img_dir: str, transform: transforms):\n",
    "        self.img_path_list = list()\n",
    "        self.data_root_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        for driver in os.listdir(self.data_root_dir):\n",
    "            for sub_dir in os.listdir(self.data_root_dir + os.sep + driver):\n",
    "                for img in os.listdir(self.data_root_dir + os.sep + driver + os.sep + sub_dir):\n",
    "                    self.img_path_list.append(self.data_root_dir + os.sep + driver + os.sep + sub_dir + os.sep + img)\n",
    "                 \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.img_path_list[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "           img = self.transform(img) \n",
    "        \n",
    "        return img, 1\n",
    "\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, img_dir: str, batch_size: int = 16, n_workers: int = 8):\n",
    "        super().__init__()\n",
    "        self.img_dir = img_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = n_workers\n",
    "        self.transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = DataModulePt(self.img_dir, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size, shuffle=False)\n",
    "   "
   ],
   "id": "adc9e60ca763f498",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:39:57.785438Z",
     "start_time": "2024-04-16T11:39:57.771439Z"
    }
   },
   "cell_type": "code",
   "source": "data = DataModule(img_dir='d:\\\\drowsy_dataset\\\\image', batch_size=16, n_workers=1)",
   "id": "6cb15e1692ffa6cc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:51:08.598766Z",
     "start_time": "2024-04-16T11:51:08.579764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18()\n",
    "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, 2)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img, label = batch\n",
    "        label = torch.randint(0, 2, size=len(img))\n",
    "        pred = self.forward(img)\n",
    "        loss = self.criterion(pred, label)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "   \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img, label = batch\n",
    "        pred = self.forward(img)\n",
    "        loss = self.criterion(pred, label)\n",
    "        self.log('val_loss', loss)\n",
    " \n",
    "        return loss\n",
    "   \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "        return optimizer\n",
    "    "
   ],
   "id": "f8ecf74cfd5bd42d",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:51:10.195127Z",
     "start_time": "2024-04-16T11:51:10.077128Z"
    }
   },
   "cell_type": "code",
   "source": "drowsy_det_model = Model()\n",
   "id": "7a53394851e376a7",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:51:11.144464Z",
     "start_time": "2024-04-16T11:51:10.904421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices='auto', max_epochs=10)\n",
    "trainer.fit(model=drowsy_det_model, datamodule=data)"
   ],
   "id": "1e02d7717cfdc88",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | ResNet           | 11.2 M\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.710    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70e87745f16e49caaf0466fce040476d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unexpected type <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mTrainer(accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m'\u001B[39m, devices\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrowsy_det_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[0;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[0;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[0;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[0;32m    576\u001B[0m     ckpt_path,\n\u001B[0;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    579\u001B[0m )\n\u001B[1;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[0;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[0;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[0;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1031\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1029\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[0;32m   1030\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m isolate_rng():\n\u001B[1;32m-> 1031\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_sanity_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m   1033\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mrun()\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1060\u001B[0m, in \u001B[0;36mTrainer._run_sanity_check\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1057\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_callback_hooks(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_sanity_check_start\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1059\u001B[0m \u001B[38;5;66;03m# run eval step\u001B[39;00m\n\u001B[1;32m-> 1060\u001B[0m \u001B[43mval_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1062\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_callback_hooks(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_sanity_check_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1064\u001B[0m \u001B[38;5;66;03m# reset logger connector\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:182\u001B[0m, in \u001B[0;36m_no_grad_context.<locals>._decorator\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    180\u001B[0m     context_manager \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mno_grad\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context_manager():\n\u001B[1;32m--> 182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:128\u001B[0m, in \u001B[0;36m_EvaluationLoop.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    127\u001B[0m     dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 128\u001B[0m     batch, batch_idx, dataloader_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m previous_dataloader_idx \u001B[38;5;241m!=\u001B[39m dataloader_idx:\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;66;03m# the dataloader has changed, notify the logger connector\u001B[39;00m\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_store_dataloader_outputs()\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:133\u001B[0m, in \u001B[0;36m_PrefetchDataFetcher.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    130\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatches\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone:\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;66;03m# this will run only when no pre-fetching was done.\u001B[39;00m\n\u001B[1;32m--> 133\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__next__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    135\u001B[0m     \u001B[38;5;66;03m# the iterator is empty\u001B[39;00m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:60\u001B[0m, in \u001B[0;36m_DataFetcher.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_profiler()\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 60\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:341\u001B[0m, in \u001B[0;36mCombinedLoader.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _ITERATOR_RETURN:\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 341\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    342\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator, _Sequential):\n\u001B[0;32m    343\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:142\u001B[0m, in \u001B[0;36m_Sequential.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    139\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 142\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterators\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;66;03m# try the next iterator\u001B[39;00m\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_next_iterator()\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[7], line 20\u001B[0m, in \u001B[0;36mDataModulePt.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     17\u001B[0m img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_path_list[idx])\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform:\n\u001B[1;32m---> 20\u001B[0m    img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m \n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img, \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:346\u001B[0m, in \u001B[0;36mResize.forward\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m    339\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    340\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    344\u001B[0m \u001B[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mantialias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torchvision\\transforms\\functional.py:462\u001B[0m, in \u001B[0;36mresize\u001B[1;34m(img, size, interpolation, max_size, antialias)\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(size) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    457\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    458\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_size should only be passed if size specifies the length of the smaller edge, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    459\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi.e. size should be an int or a sequence of length 1 in torchscript mode.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    460\u001B[0m         )\n\u001B[1;32m--> 462\u001B[0m _, image_height, image_width \u001B[38;5;241m=\u001B[39m \u001B[43mget_dimensions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(size, \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m    464\u001B[0m     size \u001B[38;5;241m=\u001B[39m [size]\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torchvision\\transforms\\functional.py:75\u001B[0m, in \u001B[0;36mget_dimensions\u001B[1;34m(img)\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F_t\u001B[38;5;241m.\u001B[39mget_dimensions(img)\n\u001B[1;32m---> 75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF_pil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_dimensions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Workspace\\Python\\drowsy_detection\\venv\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py:33\u001B[0m, in \u001B[0;36mget_dimensions\u001B[1;34m(img)\u001B[0m\n\u001B[0;32m     31\u001B[0m     width, height \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39msize\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [channels, height, width]\n\u001B[1;32m---> 33\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(img)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: Unexpected type <class 'numpy.ndarray'>"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:19:33.648205Z",
     "start_time": "2024-04-12T10:19:33.628206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_feature_dataset = train_dataset[feature_column_names]\n",
    "train_feature_data = train_feature_dataset.to_numpy()\n",
    "\n",
    "train_target_dataset = train_dataset[target_column_names]\n",
    "train_target_data = train_target_dataset.to_numpy().astype(np.uint8)\n",
    "train_target_data = 1-train_target_data"
   ],
   "id": "8a02fb1c63664d6a",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:19:35.926841Z",
     "start_time": "2024-04-12T10:19:35.913834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_target_dataset = test_dataset[target_column_names]\n",
    "test_target_data = test_target_dataset.to_numpy().astype(np.uint8)\n",
    "\n",
    "test_feature_dataset = test_dataset[feature_column_names]\n",
    "test_feature_data = test_feature_dataset.to_numpy()\n",
    "test_target_data = 1-test_target_data"
   ],
   "id": "8d59a42378a76162",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 179,
   "source": [
    "face_width = train_feature_data[:, 2] - train_feature_data[:, 0]\n",
    "face_height = train_feature_data[:, 3] - train_feature_data[:, 1]"
   ],
   "id": "5fab418b52c90b4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[211.        , 434.        , 483.        , ...,   7.28010989,\n",
       "        272.        , 476.        ],\n",
       "       [320.        , 468.        , 566.        , ...,   9.05538514,\n",
       "        246.        , 464.        ],\n",
       "       [284.        , 506.        , 600.        , ...,   8.54400375,\n",
       "        316.        , 436.        ],\n",
       "       ...,\n",
       "       [232.        , 474.        , 542.        , ...,  12.04159458,\n",
       "        310.        , 485.        ],\n",
       "       [200.        , 294.        , 534.        , ...,  11.        ,\n",
       "        334.        , 525.        ],\n",
       "       [212.        , 374.        , 545.        , ...,  13.03840481,\n",
       "        333.        , 596.        ]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 180,
   "source": [
    "train_feature_data = np.concatenate((train_feature_data, face_width.reshape(-1, 1)), axis=1)\n",
    "train_feature_data = np.concatenate((train_feature_data, face_height.reshape(-1, 1)), axis=1)\n",
    "train_feature_data"
   ],
   "id": "61c9cf5fdaf5bf97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:18:29.667089Z",
     "start_time": "2024-04-12T10:18:29.654086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "face_width = test_feature_data[:, 2] - test_feature_data[:, 0]\n",
    "face_height = test_feature_data[:, 3] - test_feature_data[:, 1]"
   ],
   "id": "8eedca452632c759",
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:18:29.742610Z",
     "start_time": "2024-04-12T10:18:29.724093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_feature_data = np.concatenate((test_feature_data, face_width.reshape(-1, 1)), axis=1)\n",
    "test_feature_data = np.concatenate((test_feature_data, face_height.reshape(-1, 1)), axis=1)\n",
    "test_feature_data"
   ],
   "id": "43fe9857f579b6de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[226.        , 505.        , 538.        , ...,  13.41640786,\n",
       "        312.        , 459.        ],\n",
       "       [151.        , 246.        , 470.        , ...,  16.03121954,\n",
       "        319.        , 516.        ],\n",
       "       [151.        , 522.        , 416.        , ...,   6.40312424,\n",
       "        265.        , 450.        ],\n",
       "       ...,\n",
       "       [260.        , 435.        , 560.        , ...,  14.03566885,\n",
       "        300.        , 417.        ],\n",
       "       [288.        , 411.        , 579.        , ...,  11.04536102,\n",
       "        291.        , 436.        ],\n",
       "       [260.        , 448.        , 560.        , ...,   9.        ,\n",
       "        300.        , 432.        ]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:19:58.582724Z",
     "start_time": "2024-04-12T10:19:58.571723Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(test_target_data[:, 0], pred_data[:, 0])",
   "id": "f8f6aedf8e1fa3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1971,   57],\n",
       "       [ 168,  117]], dtype=int64)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:20:01.521333Z",
     "start_time": "2024-04-12T10:20:01.515333Z"
    }
   },
   "cell_type": "code",
   "source": "accuracy_score(test_target_data[:, 0], pred_data[:, 0])",
   "id": "9b3090348984f9b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9027237354085603"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:20:03.364849Z",
     "start_time": "2024-04-12T10:20:03.351850Z"
    }
   },
   "cell_type": "code",
   "source": "precision_score(test_target_data[:, 0], pred_data[:, 0])",
   "id": "4e785eb0a553934c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6724137931034483"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:20:05.396701Z",
     "start_time": "2024-04-12T10:20:05.383700Z"
    }
   },
   "cell_type": "code",
   "source": "recall_score(test_target_data[:, 0], pred_data[:, 0])",
   "id": "52f0f398e10950eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4105263157894737"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:20:06.857341Z",
     "start_time": "2024-04-12T10:20:06.844341Z"
    }
   },
   "cell_type": "code",
   "source": "f1_score(test_target_data[:, 0], pred_data[:, 0])",
   "id": "695b98df8844c4fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5098039215686274"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:18:30.375070Z",
     "start_time": "2024-04-12T10:18:30.362070Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(test_target_data[:, 1], pred_data[:, 1])",
   "id": "67f5db3ed9743e0b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2004,   49],\n",
       "       [ 152,  108]], dtype=int64)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:18:30.390074Z",
     "start_time": "2024-04-12T10:18:30.377070Z"
    }
   },
   "cell_type": "code",
   "source": "accuracy_score(test_target_data[:, 1], pred_data[:, 1])",
   "id": "96bb09869cb50b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130998702983139"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:18:30.405073Z",
     "start_time": "2024-04-12T10:18:30.393073Z"
    }
   },
   "cell_type": "code",
   "source": "precision_score(test_target_data[:, 1], pred_data[:, 1])",
   "id": "9ebe013d5213b86b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6878980891719745"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:18:30.420071Z",
     "start_time": "2024-04-12T10:18:30.406074Z"
    }
   },
   "cell_type": "code",
   "source": "recall_score(test_target_data[:, 1], pred_data[:, 1])",
   "id": "2ce2c10ddfa2a3b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4153846153846154"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:18:30.435071Z",
     "start_time": "2024-04-12T10:18:30.421074Z"
    }
   },
   "cell_type": "code",
   "source": "f1_score(test_target_data[:, 1], pred_data[:, 1])",
   "id": "cd322d7c42a88d12",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5179856115107914"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:24.863816Z",
     "start_time": "2024-04-12T09:58:24.848816Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6f995595ea7a782d",
   "outputs": [],
   "execution_count": 95
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
